# -*- coding: utf-8 -*-
"""Telecom_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fso0XOGF9rp93_8bfXj0gsrsbwQ6PGVi
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
# plt.interactive(True)
# plt.ion()
# matplotlib.is_interactive()
import matplotlib.patches as patches
from matplotlib.path import Path
import sklearn
import warnings
warnings.filterwarnings("ignore")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,roc_auc_score, roc_curve, f1_score, accuracy_score
from sklearn.metrics import make_scorer, precision_score, precision_recall_curve
from sklearn.metrics import recall_score
import warnings
warnings.filterwarnings('ignore')

print(sklearn.__version__)
pd.set_option('display.max_columns',None)
pd.set_option('display.max_rows',None)
pd.set_option("display.precision", 2)
from IPython.display import display

from google.colab import files
uploaded = files.upload()

import pandas as pd

def load_and_style_dataframe(file_path):
    """
    Loads a CSV file into a DataFrame, sets display options, and styles the first few rows.

    Parameters:
    - file_path (str): The path to the CSV file.

    Returns:
    - pd.DataFrame: The loaded DataFrame.
    - pd.io.formats.style.Styler: The styled DataFrame.
    """
    # Load the CSV file into a DataFrame
    df = pd.read_csv(file_path)

    # Set display options
    pd.set_option("display.max_columns", None)
    pd.set_option("display.max_colwidth", None)

    # Style the DataFrame
    df.head().style.set_properties(**{
        'background-color': 'orange',
        'color': 'white',
        'border-color': 'darkblack'
    })

    return df

# Example usage:
file_path = "telecom_customer_churn.csv"
df = load_and_style_dataframe(file_path)
df.head()  # Display the first few rows of the DataFrame

df.head()

"""**<span style="font-size: 13px;"> We have read dataset using pandas read method. </span>**
**<span style="font-size: 13px;">Now explore the data. </span>**>

**<span style="font-size: 13px;">To explore, process and further investigation on the data, as a Data Analyst, Data Scientist and Machine Learning engineer we must know the meaning and definitation of each and every columns of dataset.** </span>

**<font size="1"> Attributes Definitation** </font>
>

- **As this is the supervised machine learning problem which has lebelled data. So let's first define the independent variables.**
- **CustomerID**: CustomerID define the ID of each individual customer, which should be unique for each.
- **Gender**: Gender define the classification of customer on the basis of gender which values are eithe male or female.
- **Age**: Define the age of customers.
- **Tenure**: Define the time in months that customers have been using internet.
- **MonthlyCharges**: Charges for customers for internet service.
- **TotalCharges**: This is the charge for internet coonnection plus service charge plus monthly fee.
- **Contract**: Define the customers contract for internet service. Once the contrace completed customers has to do repay for service continution.
- **PaymentMethod**: This is the payment channel that customers use to do payment for services.
- **InternetService**: This is the service that customers using for the internet services like optic fiber etc.
- **OnlineSecurity**: Define the customers status for who are using online security of the internet service.
- **OnlineBackup**: Define the customers who are having online backup of their services.
- **DeviceProtection**: Customers who have been using deviceprotection feature of the internet service.
- **TechnicalSupport**: Defines customers who have been taking technical support of the service.
- **StreamingTV**: Customers who are using the feature StreamingTV of the service.
- **StreamingMovies**: Customers who have been using the feature StreamingMovies of the service.-  **Churn: Which is the dependent variable which values are depend on the values of independent variables. Here churn represents the customers who have churned and not churned. so on the basis of independent variable we can predict the customers who are going to leave the service(churn) in the future or near future. We will do that using machine learning algorithms**
"""

df.describe()

"""**The describe() method in pandas is used to generate descriptive statistics that summarize the central tendency, dispersion, and shape of a datasetâ€™s distribution, excluding NaN values by default.**

**For Numerical data it gives the following info.**
- count: The number of non-null entries.
- mean: The mean (average) of the values.
- std: The standard deviation of the values.
- min: The minimum value.
- 25%: The 25th percentile (first quartile).
- 50%: The 50th percentile (median or second quartile).
- 75%: The 75th percentile (third quartile).
- max: The maximum value.

**We can use describe() method for categorical variables also.**
"""

df.describe(include='all')

"""**For categorical variables it provides the following info.**
- count: The number of non-null entries.
- unique: The number of unique values.
- top: The most frequent value (mode).
- freq: The frequency of the top value.

**Now, Identify the duplicate values in data set and removes them and we don't need to keep duplicates data in dataset so that we ensure data integrity and performance.**
"""

def find_duplicates(df):
    """
    This function identifies and prints duplicate rows in a DataFrame based on all columns.

    Parameters:
    df (pd.DataFrame): The DataFrame to check for duplicates.

    Returns:
    pd.DataFrame: A DataFrame containing the duplicate rows.
    """
    duplicates = df.duplicated()
    print("Duplicate rows (based on all columns):")
    print(df[duplicates])
    return df[duplicates]

duplicates = find_duplicates(df)

df.duplicated().sum()

"""**There are no any duplicate data in our data set.**

**Now remove the unnecessary variables from our data set. Unnecessary variables are variables which's presence in data set doesnot effect in our business requirement.**

**Once we deeply observed the data we can say CustomerID is not necessary variable in our dataset. So let's remove the variable permanently.**
"""

# df.drop(columns=['CustomerID'], inplace=True)
import pandas as pd

def drop_customer_id(df):
    """
    This function drops the 'CustomerID' column from the DataFrame in place.

    Parameters:
    df (pd.DataFrame): The DataFrame from which to drop the 'CustomerID' column.

    Returns:
    None
    """
    df.drop(columns=['CustomerID'], inplace=True)

drop_customer_id(df)

"""**Now let's check the data type of each columns.**"""

df.dtypes

"""**At this point we don't need to change the data type of any column. As all the variables are in correct type.**

**Check the null values in dataset and treat them accordingly to ensure the data completeness**
"""

import pandas as pd

def null_proportion(df):
    """
    This function calculates the proportion of null values in each column of the DataFrame
    and divides these proportions by 100.

    Parameters:
    df (pd.DataFrame): The DataFrame to check for null values.

    Returns:
    pd.Series: A Series containing the proportion of null values in each column, divided by 100.
    """
    null_counts = df.isnull().sum()
    null_proportion = null_counts / len(df) / 100
    return null_proportion

proportion = null_proportion(df)
print(proportion)

"""**There is no any null value in any column of the dataset. so we don't need to do anything for null values.**

**Now let's check the unique values of categorical variables,  So that we know the types and uniqueness of values for columns.**

**Let's check the unique values of gender in dataset.**
"""

def analyze_gender(df):
    """
    This function prints the unique values in the 'Gender' column and counts the total number of male customers.

    Parameters:
    df (pd.DataFrame): The DataFrame containing the 'Gender' column.

    Returns:
    None
    """
    unique_genders = df['Gender'].unique()
    count_male = (df['Gender'] == 'Male').sum()

    print("Unique genders:", unique_genders)
    print("Total number of male customers:", count_male)

analyze_gender(df)

"""**Let's check the weight of each unique value in the respective column**

**We have 5013 male customers from the 10000 customers.**
"""

def analyze_gender(df):
    """
    This function prints the unique values in the 'Gender' column and counts the total number of female customers.

    Parameters:
    df (pd.DataFrame): The DataFrame containing the 'Gender' column.

    Returns:
    None
    """
    unique_genders = df['Gender'].unique()
    count_female = (df['Gender'] == 'Female').sum()

    print("Unique genders:", unique_genders)
    print("Total number of female customers:", count_female)

analyze_gender(df)

"""**We have 4987 female customers from 10000 customers.**

**Now, let's check the uniqueness of customers interms of Contract. and count the weight of each unique value**
"""

def contract_counts(df):
    # Unique values in the Contract column
    unique_contracts = df.Contract.unique()

    # Counting occurrences of each contract type
    monthly_contract_count = (df["Contract"] == "Monthly").sum()
    quarterly_contract_count = (df["Contract"] == "Quarterly").sum()
    semi_annually_contract_count = (df["Contract"] == "Semi Annually").sum()
    annually_contract_count = (df["Contract"] == "Annually").sum()

    # Printing the counts
    print("Unique contracts:", unique_contracts)
    print("Total customers having monthly contract:", monthly_contract_count)
    print("Total customers having quarterly contract:", quarterly_contract_count)
    print("Total customers having semi annually contract:", semi_annually_contract_count)
    print("Total customers having annually contract:", annually_contract_count)

contract_counts(df)

"""**We have total 2428 customers from 10000 customers who has annually contract with the company**

**There is no such difference in distribution of  customers interms of contract as all values are close.**

**Now let's check theuniqueness of customers interms of PaymentMethod. And count the weight of all the unique value**
"""

def count_payment_methods(df):
    # Unique payment methods
    unique_values = df["PaymentMethod"].unique()

    # Iterate over each unique payment method
    for value in unique_values:
        # Count the number of customers for each payment method
        count = (df["PaymentMethod"] == value).sum()
        # Print the result
        print(f"Total customers who have done payment through {value}: {count}")


# Call the function with your DataFrame
count_payment_methods(df)

"""**Let's check the uniqueness of customers interms of InternerService**"""

import pandas as pd

def summarize_internet_services(df):
    # Unique internet service types
    unique_services = df["InternetService"].unique()
    print("Unique Internet Service Types:", unique_services)

    # Count of customers with Fiber optic internet service
    fiber_internet_service = (df["InternetService"] == "Fiber optic").sum()
    print("Customers with FIBER OPTIC internet service:", fiber_internet_service)

    # Count of customers with No internet service
    no_internet_service = (df["InternetService"] == "No").sum()
    print("Customers with no internet service:", no_internet_service)

    # Count of customers with DSL internet service
    dsl_internet_service = (df["InternetService"] == "DSL").sum()
    print("Customers having DSL internet service:", dsl_internet_service)

summarize_internet_services(df)

"""**Let's check the customers having online security**"""

def count_customers_with_online_security(df, column_name):
    customer_having_online_security = (df[column_name] == "Yes").sum()
    customer_not_having_online_security = (df[column_name] == "No").sum()

    print("Customers having", column_name + ":", customer_having_online_security)
    print("Customers not having", column_name + ":", customer_not_having_online_security)

count_customers_with_online_security(df, "OnlineSecurity")

def count_customers_by_category(df, column, category):
    count = (df[column] == category).sum()
    return count


online_backup_yes = count_customers_by_category(df, "OnlineBackup", "Yes")
online_backup_no = count_customers_by_category(df, "OnlineBackup", "No")

print("Customer having online backup:", online_backup_yes)
print("Customers not having online backup:", online_backup_no)

def count_customers_with_device_protection(df, category="DeviceProtection"):
    customer_with_device_protection = (df[category] == "Yes").sum()
    customer_without_device_protection = (df[category] == "No").sum()

    print(f"Customer having {category.lower()} protection: ", customer_with_device_protection)
    print(f"Customers not having {category.lower()} protection:", customer_without_device_protection)

count_customers_with_device_protection(df)

def count_customers_by_tech_support(df, column_name):
    customer_with_tech_support = (df[column_name] == "Yes").sum()
    customer_without_techsupport = (df[column_name] == "No").sum()

    print("Customers who have tech support:", customer_with_tech_support)
    print("Customers who do not have tech support:", customer_without_techsupport)

# Call the function with your DataFrame and column name
count_customers_by_tech_support(df, "TechSupport")

def count_customers_by_StreamingTV(df, column_name):
    customer_with_StreamingTV = (df[column_name] == "Yes").sum()
    customer_without_StreamingTV = (df[column_name] == "No").sum()

    print("Customers who have StreamingTV:", customer_with_StreamingTV)
    print("Customers who do not StreamingTV:", customer_without_StreamingTV)

# Call the function with your DataFrame and column name
count_customers_by_StreamingTV(df, "StreamingTV")

def count_customers_by_StreamingMovies(df, column_name):
    customer_with_StreamingMovies = (df[column_name] == "Yes").sum()
    customer_without_StreamingMovies = (df[column_name] == "No").sum()

    print("Customers who have StreamingMovies:", customer_with_StreamingMovies)
    print("Customers who do not StreamingMovies:", customer_without_StreamingMovies)

# Call the function with your DataFrame and column name
count_customers_by_StreamingMovies(df, "StreamingMovies")

def count_churn_customers(df):
    churn = (df["Churn"] == "Yes").sum()
    not_churn = (df["Churn"] == "No").sum()
    print("Churned customers:", churn)
    print("Customers who didn't churn:", not_churn)

count_churn_customers(df)

"""**We have almost completed the basic Data Exploration task.
Let's move to the Data Visualization and EDA part.**

***Exploratory Data Analysis (EDA) is a method of analyzing datasets to understand their main characteristics. It involves summarizing data features, detecting patterns, and uncovering relationships through visual and statistical techniques. EDA helps in gaining insights and formulating hypotheses for further analysis.***

**Before we do EDA, lets separate Numerical and categorical variables for easy analysis.**
"""

def seperate_variables(df):
    cat_cols = df.select_dtypes(include=['object']).columns
    num_cols = df.select_dtypes(include=np.number).columns.tolist()

    print("Categorical Variables:")
    print(cat_cols)

    print("\nNumerical Variables:")
    print(num_cols)


seperate_variables(df)

num_cols=df.select_dtypes(include=np.number).columns.tolist()
def analyze_numeric_columns(df, num_cols):

    for col in num_cols:
        print(col)
        print('Skew :', round(df[col].skew(), 2))

        plt.figure(figsize=(15, 4))

        plt.subplot(1, 2, 1)
        df[col].hist(grid=False)
        plt.ylabel('count')

        plt.subplot(1, 2, 2)
        sns.boxplot(x=df[col])

        plt.show()
analyze_numeric_columns(df, num_cols)

import matplotlib.pyplot as plt
import seaborn as sns

def plot_categorical_variables(df):
    fig, axes = plt.subplots(2, 2, figsize=(18, 18))
    fig.suptitle('Bar plot for all categorical variables in the dataset')

    sns.countplot(ax=axes[0, 0], x='Gender', data=df, color='blue',
                  order=df['Gender'].value_counts().index)

    sns.countplot(ax=axes[0, 1], x='Contract', data=df, color='orange',
                  order=df['Contract'].value_counts().index)

    sns.countplot(ax=axes[1, 0], x='PaymentMethod', data=df, color='purple',
                  order=df['PaymentMethod'].value_counts().index)

    sns.countplot(ax=axes[1, 1], x='InternetService', data=df, color='red',
                  order=df['InternetService'].value_counts().index)

    sns.countplot(ax=axes[0, 1], x='OnlineSecurity', data=df, color='pink',
                  order=df['OnlineSecurity'].value_counts().index)

    sns.countplot(ax=axes[1, 1], x='OnlineBackup', data=df, color='yellow',
                  order=df['OnlineBackup'].value_counts().index)

    sns.countplot(ax=axes[1, 1], x='DeviceProtection', data=df, color='green',
                  order=df['DeviceProtection'].value_counts().index)

    sns.countplot(ax=axes[1, 1], x='TechSupport', data=df, color='black',
                  order=df['TechSupport'].value_counts().index)

    sns.countplot(ax=axes[1, 1], x='StreamingTV', data=df, color='red',
                  order=df['StreamingTV'].value_counts().index)

    sns.countplot(ax=axes[1, 1], x='StreamingMovies', data=df, color='pink',
                  order=df['StreamingMovies'].value_counts().index)

    plt.tight_layout()
    plt.show()


plot_categorical_variables(df)

# plt.figure(figsize=(6,4))
# sns.countplot(x="Gender", data=df, palette="dark")
# plt.xlabel("Gender", fontsize=10)
# plt.show()

"""**From the above chart we can see the weight of customers in basis of gender.**"""

sns.set(rc={"figure.figsize":(6,4)})
sns.distplot(df["TotalCharges"], kde=True, color="orange", bins=20)

"""**From the above chart we can say that most of the customers paying total charges from 20k to 70k approximately**"""

sns.set(rc={"figure.figsize":(6,4)})
sns.distplot(df["Age"], kde=True, color="orange", bins=20)

"""**From the above chart we can conclude that most of the customer's age falls from 20 to 70**"""

sns.set(rc={"figure.figsize":(6,4)})
sns.distplot(df["MonthlyCharges"], kde=True, color="orange", bins=20)

"""**By seeing the above chart we can conclude that most of the customers paying monthly charge from 2k to 11k.**"""

plt.figure(figsize=(8,6))
sns.boxplot(data=df)
plt.show()

def remove_outlier(col):
    sorted(col)
    Q1,Q3 = col.quantile([0.25,0.75])
    IQR = Q3 - Q1
    lower_range = Q1 - (1.5 * IQR)
    upper_range = Q3 + (1.5 * IQR)
    return lower_range,upper_range

lower_range,upper_range = remove_outlier(df["TotalCharges"])
df["TotalCharges"] = np.where(df["TotalCharges"] > upper_range,
upper_range, df["TotalCharges"])
df["TotalCharges"] = np.where(df["TotalCharges"] < lower_range,
lower_range, df["TotalCharges"])

# plt.figure(figsize=(8,6))
# sns.boxplot(data=df)
# plt.show()

df.nunique().plot(kind='bar')
plt.title('No of unique values in the dataset')
plt.show()

sns.displot(data=df, x="Age", hue="Contract", col="Gender", kind="kde");

sns.displot(data=df, x="Age", hue="PaymentMethod", col="Gender", kind="kde");

sns.kdeplot( data=df, x="Tenure", hue="InternetService", fill=True, common_norm=False, palette="tab10");

def plot_pie_chart(df):
    # Calculate value counts
    value_counts = df["Contract"].value_counts()

    # Define labels, sizes, and colors
    labels = value_counts.index
    sizes = value_counts.values
    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']  # You can customize the colors here

    # Create the pie chart
    plt.figure(figsize=(10, 6))
    wedges, texts, autotexts = plt.pie(sizes, labels=labels, colors=colors,
                                       autopct='%1.1f%%', shadow=True, startangle=140,
                                       wedgeprops=dict(edgecolor='w'))

    # Customizing text properties
    plt.setp(texts, size=10, weight='bold', color='black')
    plt.setp(autotexts, size=9, weight='bold', color='white')

    # Customizing the legend
    plt.legend(wedges, labels, title="Contract", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

    # Adding a title
    plt.title(f'Distribution of {"Contract"}', fontsize=14, weight='bold')

    # Ensuring the pie chart is circular
    plt.axis('equal')

    # Display the plot
    plt.show()


plot_pie_chart(df)

df.head(2)

import matplotlib.pyplot as plt

def plot_pie_chart(df, colors=None, title=None):
    """
    Function to plot a pie chart based on value counts of a specified column in a dataframe.

    Parameters:
    - dataframe: pandas DataFrame containing the data
    - column_name: string, name of the column in the dataframe for which to plot the pie chart
    - colors: list of strings, optional, colors for each slice of the pie chart
    - title: string, optional, title of the pie chart

    Returns:
    - None (displays the pie chart using matplotlib)
    """
    # Count the occurrences of each unique value in the specified column
    value_counts = df["PaymentMethod"].value_counts()

    # Define labels and sizes for the pie chart
    labels = value_counts.index
    sizes = value_counts.values

    # Default colors if not provided
    if colors is None:
        colors = ['#fd9999', '#66b3bf', '#9ccf99', '#ffff99']

    # Create the pie chart
    plt.figure(figsize=(10, 6))
    wedges, texts, autotexts = plt.pie(sizes, labels=labels, colors=colors,
                                       autopct='%1.1f%%', shadow=True, startangle=140,
                                       wedgeprops=dict(edgecolor='w'))

    # Customizing text properties
    plt.setp(texts, size=10, weight='bold', color='black')
    plt.setp(autotexts, size=9, weight='bold', color='white')

    # Adding a legend
    plt.legend(wedges, labels, title="PaymentMethod", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

    # Adding a title if specified
    if title:
        plt.title(title, fontsize=14, weight='bold')

    # Ensuring the pie chart is circular
    plt.axis('equal')

    # Display the plot
    plt.show()

# Example usage
plot_pie_chart(df, colors=['#fd9999', '#66b3bf', '#9ccf99', '#ffff99'], title='Distribution of PaymentMethod')

def plot_internet_service_distribution(df):
    # Calculate value counts for InternetService
    payminternetservice_count = df.InternetService.value_counts()

    # Define labels and sizes for the pie chart
    labels = payminternetservice_count.index
    sizes = payminternetservice_count.values

    # Colors for each slice
    colors = ['#fdff99', '#66b3bE', '#9fdf99']

    # Create the pie chart
    plt.figure(figsize=(10, 6))
    wedges, texts, autotexts = plt.pie(sizes, labels=labels, colors=colors,
                                       autopct='%1.1f%%', shadow=True, startangle=140,
                                       wedgeprops=dict(edgecolor='w'))

    # Customizing text properties
    plt.setp(texts, size=10, weight='bold', color='black')
    plt.setp(autotexts, size=9, weight='bold', color='white')

    # Customizing the legend
    plt.legend(wedges, labels, title="Internet Service Types", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

    # Adding a title
    plt.title('Distribution of Internet Service Types', fontsize=14, weight='bold')

    # Ensuring the pie chart is circular
    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # Display the plot
    plt.show()


plot_internet_service_distribution(df)

df['OnlineSecurity'].value_counts().plot(kind='pie', autopct='%.2f', labels=df['OnlineSecurity'])

df['OnlineBackup'].value_counts().plot(kind='pie', autopct='%.2f', labels=df['OnlineBackup'])

df['DeviceProtection'].value_counts().plot(kind='pie', autopct='%.2f', labels=df['DeviceProtection'])

df['TechSupport'].value_counts().plot(kind='pie', autopct='%.2f', labels=df['TechSupport'])

df['StreamingTV'].value_counts().plot(kind='pie', autopct='%.2f', labels=df['StreamingTV'])

df['StreamingMovies'].value_counts().plot(kind='pie', autopct='%.2f', labels=df['StreamingMovies'])

df['InternetService'].value_counts()

plt.figure(figsize=(10,5))
df['InternetService'].value_counts().plot(kind='bar')
plt.title('Customer InternetService')
plt.xlabel('Internet Service')
plt.ylabel('Count')
plt.ylim(0, 6000)

plt.figure(figsize=(10,5))
df['Contract'].value_counts().plot(kind='bar')
plt.title('Customer Contract')
plt.xlabel('Contract Type')
plt.ylabel('Count')
plt.ylim(0, 6000)

df['PaymentMethod'].value_counts().plot(kind='bar')
plt.title('Customer Payment Method')
plt.xlabel('Payment Type')
plt.ylabel('Count')
plt.ylim(0, 6000)

df['InternetService'].value_counts().plot(kind='bar')
plt.title('Customer Internet Service')
plt.xlabel('Internet Service Type')
plt.ylabel('Count')
plt.ylim(0, 6000)

def calculate_mean_age_by_gender(df):
    """
    Calculate the mean age grouped by 'Gender' from the given DataFrame.

    Parameters:
    df (pandas.DataFrame): Input DataFrame containing 'Gender' and 'Age' columns.

    Returns:
    pandas.DataFrame: DataFrame with mean age for each gender sorted in descending order.
    """
    # Group by 'Gender' and calculate mean age, then sort in descending order
    ga = df.groupby('Gender')['Age'].mean().sort_values(ascending=False)

    # Create a new DataFrame from the grouped and sorted data
    df3 = pd.DataFrame(ga)

    return df3


calculate_mean_age_by_gender(df)

# gt = df.groupby('Gender')['Tenure'].mean().sort_values(ascending=False)
# df4 = pd.DataFrame(gt)
# df4
def calculate_mean_tenure_by_gender(df):
    """
    Calculate the mean 'Tenure' grouped by 'Gender' from the given DataFrame.

    Parameters:
    df (pandas.DataFrame): Input DataFrame containing 'Gender' and 'Tenure' columns.

    Returns:
    pandas.DataFrame: DataFrame with mean age for each gender sorted in descending order.
    """
    # Group by 'Gender' and calculate mean age, then sort in descending order
    gt = df.groupby('Gender')['Tenure'].mean().sort_values(ascending=False)

    # Create a new DataFrame from the grouped and sorted data
    df4 = pd.DataFrame(gt)

    return df4


calculate_mean_tenure_by_gender(df)

def calculate_mean_charges_by_gender(df):
    """
    Calculate the mean monthly charges grouped by gender and return a DataFrame sorted by mean charges in descending order.

    Parameters:
    - df: pandas DataFrame containing 'Gender' and 'MonthlyCharges' columns

    Returns:
    - df5: pandas DataFrame with 'Gender' as index and 'MonthlyCharges' mean values sorted in descending order
    """
    gm = df.groupby('Gender')['MonthlyCharges'].mean().sort_values(ascending=False)
    df5 = pd.DataFrame(gm)
    return df5
calculate_mean_charges_by_gender(df)

# gto = df.groupby('Gender')['TotalCharges'].mean().sort_values(ascending=False)
# df6 = pd.DataFrame(gto)
# df6

def calculate_mean_total_charges_by_gender(df):
    # Group by 'Gender' and calculate mean of 'TotalCharges'
    gto = df.groupby('Gender')['TotalCharges'].mean().reset_index()

    # Sort values in descending order based on mean 'TotalCharges'
    gto_sorted = gto.sort_values(by='TotalCharges', ascending=False).reset_index(drop=True)

    return gto_sorted

calculate_mean_total_charges_by_gender(df)

def calculate_mean_age_by_contract(df):
    # Calculate mean age grouped by 'Contract'
    mean_age_by_contract = df.groupby('Contract')['Age'].mean().sort_values(ascending=False)

    # Create a new DataFrame to store the result
    result_df = pd.DataFrame(mean_age_by_contract)

    return result_df

calculate_mean_age_by_contract(df)

def calculate_mean_tenure_by_contract(df):
    # Group by 'Contract' and calculate mean of 'Tenure'
    ct = df.groupby('Contract')['Tenure'].mean().sort_values(ascending=False)

    # Create a new DataFrame from ct
    df8 = pd.DataFrame(ct, columns=['Tenure'])

    return df8
calculate_mean_tenure_by_contract(df)

# cm = df.groupby('Contract')['MonthlyCharges'].mean().sort_values(ascending=False)
# df9 = pd.DataFrame(cm)
# df9
def calculate_mean_monthly_charges(df):
    # Group by 'Contract' and calculate the mean of 'MonthlyCharges'
    cm = df.groupby('Contract')['MonthlyCharges'].mean().sort_values(ascending=False)

    # Create a DataFrame from the Series cm
    df9 = pd.DataFrame(cm)

    return df9

calculate_mean_monthly_charges(df)

def calculate_mean_total_charges(df):
    cto = df.groupby('Contract')['TotalCharges'].mean().sort_values(ascending=False)
    df10 = pd.DataFrame(cto)
    return df10

calculate_mean_total_charges(df)

def calculate_mean_age_by_payment_method(df):
    # Group by 'PaymentMethod', calculate mean of 'Age', and sort by mean age descending
    pa = df.groupby('PaymentMethod')['Age'].mean().sort_values(ascending=False)
    df11 = pd.DataFrame(pa)  # Creating DataFrame with column 'MeanAge'
    return df11

calculate_mean_age_by_payment_method(df)

def calculate_mean_tenure_by_payment_method(df):
    pt = df.groupby('PaymentMethod')['Tenure'].mean().sort_values(ascending=False)
    df12 = pd.DataFrame(pt)
    return df12

calculate_mean_tenure_by_payment_method(df)

def calculate_mean_monthly_charges(df):
    pm = df.groupby('PaymentMethod')['MonthlyCharges'].mean().sort_values(ascending=False)
    df13 = pd.DataFrame(pm)
    return df13
calculate_mean_monthly_charges(df)

def  calculate_mean_total_charges(df):
    # Group by 'PaymentMethod' and calculate mean of 'TotalCharges'
    pto = df.groupby('PaymentMethod')['TotalCharges'].mean().sort_values(ascending=False)

    # Create a new DataFrame 'df14' from 'pto'
    df14 = pd.DataFrame(pto)

    return df14

calculate_mean_total_charges(df)

def calculate_mean_age_by_internet_service(df):
    # Group by 'InternetService' and calculate mean age
    ia = df.groupby('InternetService')['Age'].mean().sort_values(ascending=False)

    # Convert to DataFrame with column name 'Age'
    df15 = pd.DataFrame(ia, columns=['Age'])

    return df15

calculate_mean_age_by_internet_service(df)

# it = df.groupby('InternetService')['Tenure'].mean().sort_values(ascending=False)
# df16 = pd.DataFrame(it)
# df16

def calculate_mean_tenure_by_internet_service(df):
    # Group by 'InternetService', calculate mean of 'Tenure', sort in descending order
    it = df.groupby('InternetService')['Tenure'].mean().sort_values(ascending=False)

    # Create a new DataFrame 'df16' from the sorted results
    df16 = pd.DataFrame(it, columns=['Tenure'])

    return df16

calculate_mean_tenure_by_internet_service(df)

def mean_monthly_charges_by_internet_service(df):
    # Group by 'InternetService' and calculate mean of 'MonthlyCharges'
    im = df.groupby('InternetService')['MonthlyCharges'].mean()

    # Sort the result in descending order
    im_sorted = im.sort_values(ascending=False)

    # Create a DataFrame from the sorted series
    df17 = pd.DataFrame(im_sorted, columns=['MonthlyCharges'])

    return df17

mean_monthly_charges_by_internet_service(df)

def calculate_mean_total_charges(df):
    ito = df.groupby('InternetService')['TotalCharges'].mean().sort_values(ascending=False)
    df18 = pd.DataFrame(ito)
    return df18
calculate_mean_total_charges(df)

# df = ...  # Incorrect usage, trying to assign ellipsis to df
df.head()  # AttributeError: 'ellipsis' object has no attribute 'head'

num_list = ['Age', 'Tenure', 'MonthlyCharges', 'TotalCharges']
fig = plt.figure(figsize=(15,10))
for i in range(len(num_list)):
    column=num_list[i]
    sub=fig.add_subplot(2,3, i+1)
    sns.boxplot(x='Churn', y=column, data=df, palette='RdYlBu_r')

df.select_dtypes(include='object').nunique()

plt.subplot(1, 2, 2)
Age = plt.hist(df['Age'], density = True, color = "green")
plt.title("Customer Age")

plt.subplot(1, 2, 2)
Tenure = plt.hist(df['Tenure'], density = True, color = "red")
plt.title("Tenure")

plt.subplot(1, 2, 2)
MonthlyCharges = plt.hist(df['MonthlyCharges'], density = True, color = "orange")
plt.title("Monthly Charges")

plt.subplot(1, 2, 2)
TotalCharges = plt.hist(df['TotalCharges'], density = True, color = "blue")
plt.title("TotalCharges")

from scipy import stats

num_cols = df.select_dtypes(include=["int64","float64"])
def plots(num_cols, variable):
    plt.figure(figsize=(15,6))
    plt.subplot(1,2, 2)
    #num_cols[variable].hist()
    sns.distplot(num_cols[variable], kde=True, bins=10)
    plt.title(variable)
    plt.subplot(1, 2, 2)
    stats.probplot(num_cols[variable], dist="norm")
    plt.title(variable)
    plt.show()
for i in num_cols.columns:
    plots(num_cols, i)

"""**Now let's start Feature Engineering part. Here, we don't need to do much more as we just need to convert caterogical feature into numerical features. To accolplish this we will use different type of encoding methods provided by sklearn library. like label encoder, onehotencoder, ordinal encoder, binary encoder arrordingly**"""

# let's convert contract values into numerical.
from sklearn.preprocessing import LabelEncoder

# Initialize the label encoder
le = LabelEncoder()

# Fit and transform the data
df['Contract_encoded'] = le.fit_transform(df['Contract'])
df['Payment_Method'] = le.fit_transform(df['PaymentMethod'])
df['Internet_Service'] = le.fit_transform(df['InternetService'])
df['Gender_encoded'] = le.fit_transform(df['Gender'])

# Define the mapping
onlinesecurity_mapping = {'Yes': 1, 'No': 0}
onlinebackup_mapping = {'Yes':1, 'No':0}
deviceprotection_mapping = {'Yes':1, 'No':0}
techsupport_mapping = {'Yes':1, 'No':0}
streamingTV_mapping = {'Yes':1, 'No':0}
streamingmovies_mapping = {'Yes':1, 'No':0}
# Apply the mapping
df['Onlinesecurity_encoded'] = df['OnlineSecurity'].map(onlinesecurity_mapping)
df['Onlinebackup_encoded'] = df['OnlineBackup'].map(onlinebackup_mapping)
df['deviceprotection_encoded'] = df['DeviceProtection'].map(deviceprotection_mapping)
df['techsupport_encoded'] = df['TechSupport'].map(techsupport_mapping)
df['streamingTV_encoded'] = df['StreamingTV'].map(streamingTV_mapping)
df['streamingmovies_encoded'] = df['StreamingMovies'].map(streamingmovies_mapping)

df[["Gender","Gender_encoded"]]

"""**Let's encode the dependent/ target variable also using manual mapping which is effective and easy to apply.**"""

churn_mapping = {'Yes':1, 'No':0}
# Apply the mapping
df['Churned'] = df['Churn'].map(churn_mapping)

df[["Churn","Churned"]]

gc=df.groupby('Gender').sum()['Churned']
df3=pd.DataFrame(gc)
df3

cc=df.groupby('Contract').sum()['Churned']
df4=pd.DataFrame(cc)
df4

pc=df.groupby('PaymentMethod').sum()['Churned']
df5=pd.DataFrame(pc)
df5

ic=df.groupby('InternetService').sum()['Churned']
df6=pd.DataFrame(ic)
df6

pg=df.groupby('Gender').sum()['Internet_Service']
df7=pd.DataFrame(pg)
df7

# Filter for male customers who have churned and have an annual contract
filtered_df = df[(df['Gender'] == 'Male') & (df['Churn'] == 'Yes') & (df['Contract'] == 'Annually')]

count = filtered_df.shape[0]

count

df['Churned'].value_counts()

#we oversample the minority class to balance the label
# from sklearn.utils import resample
# churn_majority=df[(df['Churned']==0)]
# churn_minority=df[(df['Churned']==1)]
# churn_minority_upsampled=resample(churn_minority,
# replace=True,
# n_samples=9999,
# random_state=0)
# churn_upsampled=pd.concat([churn_minority_upsampled, churn_majority])

"""**Now Let's remove the original categorical variable from the data set to prevents redundancy and potential confusion during the modeling process. The encoded numerical values will be used by machine learning algorithms, and the original categorical columns are no longer needed**"""

# List of columns to remove
columns_to_remove = ['Gender', 'Contract','PaymentMethod', 'InternetService', 'OnlineSecurity', 'OnlineBackup',
                    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Churn']

# Correct way without reassigning
df.drop(columns=columns_to_remove,axis=1, inplace=True)
print(df)  # This will print the DataFrame correctly

df.head(3)

"""**Here, in our dtaset we can see that TotalCharges values is bit confusing as it's not the multiply of MonthlyCharges * Tenure. Example: Let's take o index row, in that row tenure is 17(probabily this is in months) and MonthlyCharges is 6365.68, if we multiply both the value is 108,216.56 but in dataset the value of TotalCharges is 339619. So probabily they have added extra services and physical devices price also. So let's do transform. Let's create a column called OverallCharges by adding MonthlyCharges and TotalCharges, which will removes the 2 variables and and add 1 variable in our datasetwhich will make our datase  little bit simple and easy to process.**


"""

# Create a column OverallCharges by adding the value of MonthlyCharges and TotalCharges.
df['OverallCharges'] = df['MonthlyCharges'] + df['MonthlyCharges']
# This code is not giving expected output. So let's check the data integrity.

df.head(2)

# Strip whitespace from columns
df['MonthlyCharges'] = df['MonthlyCharges'].astype(str).str.strip()
df['TotalCharges'] = df['TotalCharges'].astype(str).str.strip()

# Convert to numeric after stripping
df['MonthlyCharges'] = pd.to_numeric(df['MonthlyCharges'], errors='coerce')
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Additional Check: Validate each addition
for index, row in df.iterrows():
    expected = row['MonthlyCharges'] + row['TotalCharges']
    actual = row['OverallCharges']
    print(f"Row {index}: {row['MonthlyCharges']} + {row['TotalCharges']} = {actual}, Expected = {expected}, Match = {actual == expected}")

print(df.isna().sum())
print(np.isfinite(df).sum())

df['ComputedOverallCharges'] = df['MonthlyCharges'] + df['TotalCharges']

# Drop original columns.
df.drop(columns=['MonthlyCharges','TotalCharges', 'OverallCharges'],axis=1, inplace=True)

df.head(2)

df.columns

# Rename columns using a dictionary
df.rename(columns={'Onlinesecurity_encoded': 'OnlineSecurity',
                        'Onlinebackup_encoded': 'OnlineBackup',
                        'deviceprotection_encoded': 'DeviceProtection',
                        'techsupport_encoded': 'TechSupport',
                        'streamingTV_encoded': 'StreamingTV',
                        'streamingmovies_encoded': 'StreamingMovies',
                        'Contract_encoded': 'Contract',
                        'Payment_Method':'PaymentMethod',
                        'Internet_Service':'InternetService',
                        'Gender_encoded':'Gender'
                        }, inplace=True)

df.head(2)

# Reorder the columns
def reorder_columns(df, column_order):
    return df[column_order]

column_order = ['Gender', 'Age', 'Tenure','ComputedOverallCharges','Contract','PaymentMethod',
                'InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport',
                'StreamingTV', 'StreamingMovies', 'Churned']
df = reorder_columns(df, column_order)

df.head(2)

df["ComputedOverallCharges"].min()

df["ComputedOverallCharges"].max()

df['ComputedOverallCharges'].idxmin()

# import minmaxscaler and standarscaler from sklearn
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

# Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Fit and transform the data
df['ComputedOverallCharges_scaled'] = scaler.fit_transform(df[['ComputedOverallCharges']])

df.head(5)

df["Age"].min()

df["Age"].max()

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit and transform the data
df['Age_standardized'] = scaler.fit_transform(df[['Age']])

df.head(2)

# drop columns Age and ComputedOverallCharges
df.drop(columns= ['Age','ComputedOverallCharges'], axis=1, inplace=True)

df.head(2)

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit and transform the data
df['Tenure_standardized'] = scaler.fit_transform(df[['Tenure']])

df.head(2)

# Drop column Tenure.
df.drop(columns= ['Tenure'], axis=1, inplace=True)

df.head(2)

df.corr()

# Create the heatmap
plt.figure(figsize=(20, 9))
sns.heatmap(df.corr(), annot=True, cmap='plasma', center=0)
plt.title('Correlation Matrix Heatmap')
plt.show()

# Import required methods from sklearn
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier

X = df.drop('Churned', axis=1)
y = df['Churned']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Initialize and Train Random Forest Model"""

# # Initialize Random Forest classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

"""Evaluate the Model"""

# # Make predictions
y_pred = rf_model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

"""Confusion Matrix and Classification Report"""

# # Confusion matrix
# from sklearn.metrics import classification_report

conf_matrix = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:')
print(conf_matrix)

# Classification report
class_report = classification_report(y_test, y_pred)
print('Classification Report:')
print(class_report)

"""Cross-Validation Implementation"""

# import numpy as np
from sklearn.model_selection import cross_val_score, StratifiedKFold

# Define the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Define the cross-validation strategy
# StratifiedKFold is used for classification tasks to ensure each fold has roughly the same class distribution as the original dataset
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform cross-validation
cv_scores = cross_val_score(rf_model, X, y, cv=cv, scoring='accuracy')

# Print cross-validation scores
print("Cross-Validation Scores:")
print(cv_scores)

# Calculate and print mean accuracy across folds
print(f"Mean Accuracy: {np.mean(cv_scores):.2f}")

"""Initialize and Train Gradient Boosting Model"""

# # Initialize Gradient Boosting classifier
# from sklearn.ensemble import GradientBoostingClassifier
# gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)

# # Train the model
# gb_model.fit(X_train, y_train)

"""Predictions and Accuracy"""

# # Make predictions
# y_pred = gb_model.predict(X_test)

# # Calculate accuracy
# accuracy = accuracy_score(y_test, y_pred)
# print(f'Accuracy: {accuracy:.2f}')

"""Confusion Matrix and Classification Report"""

# # Confusion matrix
# conf_matrix = confusion_matrix(y_test, y_pred)
# print('Confusion Matrix:')
# print(conf_matrix)

# # Classification report
# class_report = classification_report(y_test, y_pred)
# print('Classification Report:')
# print(class_report)

"""Feature Importance"""

# # Extract feature importances
# feature_importances = gb_model.feature_importances_

# # Create a DataFrame to display feature importances
# feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
# feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# print('Feature Importances:')
# print(feature_importance_df)

import pickle

# # Load the model
# model_path = 'trained_model.pkl'
# with open(model_path, 'rb') as f:
#     model = pickle.load(f)

# Make pickle file of our model
pickle.dump(rf_model, open("churn.pkl", "wb"))

df.columns

